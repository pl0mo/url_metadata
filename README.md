WORK IN PROGRESS

A cache which saves URL metadata and content

This is meant to provide more context to any of my tools which use URLs. If I [watched some youtube video](https://github.com/seanbreckenridge/mpv-sockets/blob/master/DAEMON.md) and I have a URL, I'd like to have the subtitles for it, so I can do a text-search over all the videos I've watched. If I [read an article](https://github.com/seanbreckenridge/ffexport), I want the article text! This requests, parses and abstracts away that data for me locally, so I can just do:

```python
>>> from url_metadata import metadata
>>> metadata(url)
```

---

## Installation

Requires `python3.7+`

To install with pip, run:

    pip install git+https://github.com/seanbreckenridge/url_metadata

---

This uses:

- [lassie](https://github.com/michaelhelmick/lassie) to get generic metadata, like the title, description, opengraph information, links to images/videos on the page
- [readability](https://github.com/buriy/python-readability) to convert HTML to readable HTML content.
- [pandoc](https://pandoc.org/) to convert the parsed HTML to markdown (to allow for nicer parsing/searching)
- [youtube_subtitles_downloader](https://github.com/seanbreckenridge/youtube_subtitles_downloader) to get manual/autogenerated captions (converted to a `.srt` file) from youtube URLs

---

Usage:

TODO: add python library usage

---

Searching:

TODO: add CLI/external usage

---

This stores all of this information as individual files in a cache directory (using [`appdirs`](https://github.com/ActiveState/appdirs)). In particular, it `MD5` hashes the URL and stores information like:

```
.
└── 7
    └── b
        └── 0
            └── d952fd7265e8e4cf10b351b6f8932
                └── 000
                    ├── epoch_timestamp.txt
                    ├── key
                    ├── metadata.json
                    ├── summary.html
                    └── summary.md
```

You're free to delete any of the directories in the cache if you want, this doesn't maintain a strict index, it uses a hash of the URL and then searches for a matching `key` file. See comments [here](https://github.com/seanbreckenridge/url_metadata/blob/master/src/url_metadata/cache.py) for implementation details.

